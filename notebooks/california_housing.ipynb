{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b9ba262",
   "metadata": {},
   "source": [
    "Linear regression using\n",
    "\n",
    "Boston Housing Data\n",
    "\n",
    "dataset docs: https://www.kaggle.com/code/prasadperera/the-boston-housing-dataset/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fa6f529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import math\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "import math, copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13b00d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[   8.3252    ,   41.        ,    6.98412698, ...,    2.55555556,\n",
       "           37.88      , -122.23      ],\n",
       "        [   8.3014    ,   21.        ,    6.23813708, ...,    2.10984183,\n",
       "           37.86      , -122.22      ],\n",
       "        [   7.2574    ,   52.        ,    8.28813559, ...,    2.80225989,\n",
       "           37.85      , -122.24      ],\n",
       "        ...,\n",
       "        [   1.7       ,   17.        ,    5.20554273, ...,    2.3256351 ,\n",
       "           39.43      , -121.22      ],\n",
       "        [   1.8672    ,   18.        ,    5.32951289, ...,    2.12320917,\n",
       "           39.43      , -121.32      ],\n",
       "        [   2.3886    ,   16.        ,    5.25471698, ...,    2.61698113,\n",
       "           39.37      , -121.24      ]]),\n",
       " 'target': array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894]),\n",
       " 'frame': None,\n",
       " 'target_names': ['MedHouseVal'],\n",
       " 'feature_names': ['MedInc',\n",
       "  'HouseAge',\n",
       "  'AveRooms',\n",
       "  'AveBedrms',\n",
       "  'Population',\n",
       "  'AveOccup',\n",
       "  'Latitude',\n",
       "  'Longitude'],\n",
       " 'DESCR': '.. _california_housing_dataset:\\n\\nCalifornia Housing dataset\\n--------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 20640\\n\\n    :Number of Attributes: 8 numeric, predictive attributes and the target\\n\\n    :Attribute Information:\\n        - MedInc        median income in block group\\n        - HouseAge      median house age in block group\\n        - AveRooms      average number of rooms per household\\n        - AveBedrms     average number of bedrooms per household\\n        - Population    block group population\\n        - AveOccup      average number of household members\\n        - Latitude      block group latitude\\n        - Longitude     block group longitude\\n\\n    :Missing Attribute Values: None\\n\\nThis dataset was obtained from the StatLib repository.\\nhttps://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\\n\\nThe target variable is the median house value for California districts,\\nexpressed in hundreds of thousands of dollars ($100,000).\\n\\nThis dataset was derived from the 1990 U.S. census, using one row per census\\nblock group. A block group is the smallest geographical unit for which the U.S.\\nCensus Bureau publishes sample data (a block group typically has a population\\nof 600 to 3,000 people).\\n\\nAn household is a group of people residing within a home. Since the average\\nnumber of rooms and bedrooms in this dataset are provided per household, these\\ncolumns may take surpinsingly large values for block groups with few households\\nand many empty houses, such as vacation resorts.\\n\\nIt can be downloaded/loaded using the\\n:func:`sklearn.datasets.fetch_california_housing` function.\\n\\n.. topic:: References\\n\\n    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\\n      Statistics and Probability Letters, 33 (1997) 291-297\\n'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing = fetch_california_housing()\n",
    "\n",
    "housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88878c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.random.seed(1)\n",
    "np.random.randint(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5defc93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpers - data clean\n",
    "\n",
    "def load_data():\n",
    "    housing  = fetch_california_housing()\n",
    "    \n",
    "    df = pd.DataFrame(data= np.c_[housing['data'], housing['target']],\n",
    "                     columns= housing['feature_names'] + ['target'])\n",
    "    return df\n",
    "    \n",
    "\n",
    "def train_test_split(df):\n",
    "    n = len(df)\n",
    "    \n",
    "    # train test split (2/3 train, 1/3 test)\n",
    "    n_train = round(2/3*n)\n",
    "\n",
    "    train_df = df[:n_train]\n",
    "    test_df = df[n_train:]\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "\n",
    "def df_to_input(df):\n",
    "    m = len(df)\n",
    "    X = df['AveBedrms'].values.reshape(1, m)\n",
    "    Y = df['target'].values.reshape(1, m)\n",
    "    \n",
    "    return X, Y\n",
    "\n",
    "\n",
    "def initial_rand(X):\n",
    "    \n",
    "    np.random.seed(1)\n",
    "    \n",
    "    m = X.shape[0]\n",
    "    n = X.shape[1]\n",
    "    \n",
    "    w = np.random.randn(n).reshape(n,1) * 0.01\n",
    "    b = np.random.randint(0,100) * 0.01 \n",
    "    \n",
    "    return w, b\n",
    "\n",
    "def initial_zeros(X):\n",
    "    \n",
    "    np.random.seed(1)\n",
    "    \n",
    "    # m = number of training examples\n",
    "    m = X.shape[0]\n",
    "    \n",
    "    # n = number of features\n",
    "    n = X.shape[1]\n",
    "    \n",
    "    w = np.zeros(n).reshape(n,1)\n",
    "    b = 0\n",
    "    \n",
    "    return w, b\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ec05eaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run\n",
    "\n",
    "df = load_data()\n",
    "\n",
    "train_df, test_df = train_test_split(df) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f7111cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # show data\n",
    "# m = number of training examples\n",
    "m = train_df.values.shape[0]\n",
    "# n = number of features\n",
    "n = len(train_df.drop(columns='target').columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fc29288c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13760, 8, (13760, 8), (13760, 1))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X should be of the dimensions m, n\n",
    "\n",
    "X = train_df.drop(columns='target').values.reshape(m,n)\n",
    "Y = train_df['target'].values.reshape(m,1)\n",
    "\n",
    "m, n, X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "83b796a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]),\n",
       " 0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, b = initial_rand(X)\n",
    "\n",
    "w, b = initial_zeros(X)\n",
    "w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "544d5ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(X, w, b):\n",
    "    n = X.shape[0]\n",
    "    # reshape step important for later functions\n",
    "    Y_hat = np.dot(X, w) + b\n",
    "    return Y_hat\n",
    "\n",
    "\n",
    "def calculate_cost(X, Y, w, b):\n",
    "    m = X.shape[0]\n",
    "    Y_hat = forward_prop(X, w, b)\n",
    "    cost = np.sum((Y_hat - Y)**2 ) / (2*m)\n",
    "    return cost\n",
    "\n",
    "\n",
    "def calculate_grads(X, Y, w, b):\n",
    "    m, n = X.shape\n",
    "    Y_hat = forward_prop(X, w, b)\n",
    "    db = np.mean(Y_hat - Y)\n",
    "    dw = np.sum(((Y_hat - Y) * X.T), axis=1) / m\n",
    "    return db, dw\n",
    "\n",
    "def gradient_descent(X, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters): \n",
    "    \"\"\"\n",
    "    Performs batch gradient descent to learn theta. Updates theta by taking \n",
    "    num_iters gradient steps with learning rate alpha\n",
    "    \n",
    "    Args:\n",
    "      X (ndarray (m,n))   : Data, m examples with n features\n",
    "      y (ndarray (m,))    : target values\n",
    "      w_in (ndarray (n,)) : initial model parameters  \n",
    "      b_in (scalar)       : initial model parameter\n",
    "      cost_function       : function to compute cost\n",
    "      gradient_function   : function to compute the gradient\n",
    "      alpha (float)       : Learning rate\n",
    "      num_iters (int)     : number of iterations to run gradient descent\n",
    "      \n",
    "    Returns:\n",
    "      w (ndarray (n,)) : Updated values of parameters \n",
    "      b (scalar)       : Updated value of parameter \n",
    "      \"\"\"\n",
    "    \n",
    "    # An array to store cost J and w's at each iteration primarily for graphing later\n",
    "    J_history = []\n",
    "    w = copy.deepcopy(w_in)  #avoid modifying global w within function\n",
    "    b = b_in\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "\n",
    "        # Calculate the gradient and update the parameters\n",
    "        dj_db,dj_dw = gradient_function(X, y, w, b)   ##None\n",
    "            \n",
    "        # Update Parameters using w, b, alpha and gradient\n",
    "        w = w - alpha * dj_dw               ##None\n",
    "        b = b - alpha * dj_db               ##None\n",
    "      \n",
    "        # Save cost J at each iteration\n",
    "        if i<100000:      # prevent resource exhaustion \n",
    "            J_history.append( cost_function(X, y, w, b))\n",
    "\n",
    "        # Print cost every at intervals 10 times or as many iterations if < 10\n",
    "        if i% math.ceil(num_iters / 10) == 0:\n",
    "            print(f\"Iteration {i:4d}: Cost {J_history[-1]:8.2f}   \")\n",
    "\n",
    "        \n",
    "    return w, b, J_history #return final w,b and J history for graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f1ce590f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (13760,1) (8,13760) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [40]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5.0e-7\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# run gradient descent \u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m w_final, b_final, J_hist \u001b[38;5;241m=\u001b[39m \u001b[43mgradient_descent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_w\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_b\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mcalculate_cost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcalculate_grads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb,w found by gradient descent: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mb_final\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m0.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mw_final\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m m,_ \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mshape\n",
      "Input \u001b[0;32mIn [39]\u001b[0m, in \u001b[0;36mgradient_descent\u001b[0;34m(X, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters)\u001b[0m\n\u001b[1;32m     45\u001b[0m b \u001b[38;5;241m=\u001b[39m b_in\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_iters):\n\u001b[1;32m     48\u001b[0m \n\u001b[1;32m     49\u001b[0m     \u001b[38;5;66;03m# Calculate the gradient and update the parameters\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m     dj_db,dj_dw \u001b[38;5;241m=\u001b[39m \u001b[43mgradient_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m   \u001b[38;5;66;03m##None\u001b[39;00m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;66;03m# Update Parameters using w, b, alpha and gradient\u001b[39;00m\n\u001b[1;32m     53\u001b[0m     w \u001b[38;5;241m=\u001b[39m w \u001b[38;5;241m-\u001b[39m alpha \u001b[38;5;241m*\u001b[39m dj_dw               \u001b[38;5;66;03m##None\u001b[39;00m\n",
      "Input \u001b[0;32mIn [39]\u001b[0m, in \u001b[0;36mcalculate_grads\u001b[0;34m(X, Y, w, b)\u001b[0m\n\u001b[1;32m     17\u001b[0m Y_hat \u001b[38;5;241m=\u001b[39m forward_prop(X, w, b)\n\u001b[1;32m     18\u001b[0m db \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(Y_hat \u001b[38;5;241m-\u001b[39m Y)\n\u001b[0;32m---> 19\u001b[0m dw \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum((\u001b[43m(\u001b[49m\u001b[43mY_hat\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m db, dw\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (13760,1) (8,13760) "
     ]
    }
   ],
   "source": [
    "\n",
    "# initialize parameters\n",
    "initial_w = np.zeros_like(w)\n",
    "initial_b = 0.\n",
    "\n",
    "# some gradient descent settings\n",
    "iterations = 1000\n",
    "alpha = 5.0e-7\n",
    "\n",
    "# run gradient descent \n",
    "w_final, b_final, J_hist = gradient_descent(X, Y, initial_w, initial_b,\n",
    "                                                    calculate_cost, calculate_grads, \n",
    "                                                    alpha, iterations)\n",
    "print(f\"b,w found by gradient descent: {b_final:0.2f},{w_final} \")\n",
    "m,_ = X_train.shape\n",
    "for i in range(m):\n",
    "    print(f\"prediction: {np.dot(X_train[i], w_final) + b_final:0.2f}, target value: {y_train[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acd7aa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c245352f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
