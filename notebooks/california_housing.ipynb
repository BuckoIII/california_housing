{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d0cac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: \n",
    "#     [] resturcutre project in productionisable python project format\n",
    "#     [] experiment with including lat-long & best feature engineering approaches to model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9ba262",
   "metadata": {},
   "source": [
    "Linear regression using\n",
    "\n",
    "Boston Housing Data\n",
    "\n",
    "dataset docs: https://www.kaggle.com/code/prasadperera/the-boston-housing-dataset/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3fa6f529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import math\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "import math, copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "13b00d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _california_housing_dataset:\n",
      "\n",
      "California Housing dataset\n",
      "--------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 20640\n",
      "\n",
      "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
      "\n",
      "    :Attribute Information:\n",
      "        - MedInc        median income in block group\n",
      "        - HouseAge      median house age in block group\n",
      "        - AveRooms      average number of rooms per household\n",
      "        - AveBedrms     average number of bedrooms per household\n",
      "        - Population    block group population\n",
      "        - AveOccup      average number of household members\n",
      "        - Latitude      block group latitude\n",
      "        - Longitude     block group longitude\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "This dataset was obtained from the StatLib repository.\n",
      "https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\n",
      "\n",
      "The target variable is the median house value for California districts,\n",
      "expressed in hundreds of thousands of dollars ($100,000).\n",
      "\n",
      "This dataset was derived from the 1990 U.S. census, using one row per census\n",
      "block group. A block group is the smallest geographical unit for which the U.S.\n",
      "Census Bureau publishes sample data (a block group typically has a population\n",
      "of 600 to 3,000 people).\n",
      "\n",
      "An household is a group of people residing within a home. Since the average\n",
      "number of rooms and bedrooms in this dataset are provided per household, these\n",
      "columns may take surpinsingly large values for block groups with few households\n",
      "and many empty houses, such as vacation resorts.\n",
      "\n",
      "It can be downloaded/loaded using the\n",
      ":func:`sklearn.datasets.fetch_california_housing` function.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
      "      Statistics and Probability Letters, 33 (1997) 291-297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load & describe data\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "print(str(housing['DESCR']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "5defc93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpers - data cleaning helpers\n",
    "\n",
    "def load_data():\n",
    "    housing  = fetch_california_housing()\n",
    "    \n",
    "    df = pd.DataFrame(data= np.c_[housing['data'], housing['target']],\n",
    "                     columns= housing['feature_names'] + ['target'])\n",
    "    df = df.drop(columns=['Latitude', 'Longitude'])\n",
    "\n",
    "    return df\n",
    "    \n",
    "\n",
    "def train_test_split(df):\n",
    "    n = len(df)\n",
    "    \n",
    "    # train test split (2/3 train, 1/3 test)\n",
    "    n_train = round(2/3*n)\n",
    "\n",
    "    train_df = df[:n_train]\n",
    "    test_df = df[n_train:]\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "\n",
    "def initial_rand(X):\n",
    "    \n",
    "    np.random.seed(1)\n",
    "    \n",
    "    m = X.shape[0]\n",
    "    n = X.shape[1]\n",
    "    \n",
    "    w = np.random.randn(n).reshape(n,1) * 0.01\n",
    "    b = np.random.randint(0,100) * 0.01 \n",
    "    \n",
    "    return w, b\n",
    "\n",
    "def initial_zeros(X):\n",
    "    \n",
    "    np.random.seed(1)\n",
    "    \n",
    "    # m = number of training examples\n",
    "    m = X.shape[0]\n",
    "    \n",
    "    # n = number of features\n",
    "    n = X.shape[1]\n",
    "    \n",
    "    w = np.zeros(n).reshape(n,1).T\n",
    "    b = 0\n",
    "    \n",
    "    return w, b\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "ec05eaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run clean data functions\n",
    "\n",
    "df = load_data()\n",
    "\n",
    "train_df, test_df = train_test_split(df) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "8f7111cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set m & n\n",
    "\n",
    "# m = number of training examples\n",
    "m = train_df.values.shape[0]\n",
    "\n",
    "# n = number of features\n",
    "n = len(train_df.drop(columns='target').columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "fc29288c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13760, 6, (13760, 6), (1, 13760))"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X should be of the dimensions m, n\n",
    "\n",
    "# X should be a matrix of with m (number training examples) rows and n (number features) columns \n",
    "X = train_df.drop(columns='target').values.reshape(m,n)\n",
    "\n",
    "# Y should be a matrix with 1 row and n columns\n",
    "Y = train_df['target'].values.reshape(1,m)\n",
    "\n",
    "m, n, X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "544d5ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define gradient descent functions\n",
    "\n",
    "def forward_prop(X, w, b):\n",
    "    n = X.shape[0]\n",
    "    # reshape step important for later functions\n",
    "    Y_hat = np.dot(w, X.T) + b\n",
    "\n",
    "    return Y_hat\n",
    "\n",
    "\n",
    "def calculate_cost(X, Y, w, b):\n",
    "    m = X.shape[0]\n",
    "    Y_hat = forward_prop(X, w, b)\n",
    "    cost = np.sum((Y_hat - Y)**2 ) / (2*m)\n",
    "    return cost\n",
    "\n",
    "\n",
    "def calculate_grads(X, Y, w, b):\n",
    "    m, n = X.shape\n",
    "    Y_hat = forward_prop(X, w, b)\n",
    "    db = np.mean(Y_hat - Y)\n",
    "    dw = np.sum(((Y_hat - Y) * X.T), axis=1) / m\n",
    "    return db, dw\n",
    "\n",
    "def gradient_descent(X, y, w_in, b_in, cost_function, gradient_function, alpha, num_iters): \n",
    "    \"\"\"\n",
    "    Performs batch gradient descent to learn theta. Updates theta by taking \n",
    "    num_iters gradient steps with learning rate alpha\n",
    "    \n",
    "    Args:\n",
    "      X (ndarray (m,n))   : Data, m examples with n features\n",
    "      y (ndarray (m,))    : target values\n",
    "      w_in (ndarray (n,)) : initial model parameters  \n",
    "      b_in (scalar)       : initial model parameter\n",
    "      cost_function       : function to compute cost\n",
    "      gradient_function   : function to compute the gradient\n",
    "      alpha (float)       : Learning rate\n",
    "      num_iters (int)     : number of iterations to run gradient descent\n",
    "      \n",
    "    Returns:\n",
    "      w (ndarray (n,)) : Updated values of parameters \n",
    "      b (scalar)       : Updated value of parameter \n",
    "      \"\"\"\n",
    "    \n",
    "    # An array to store cost J and w's at each iteration primarily for graphing later\n",
    "    J_history = []\n",
    "    w = copy.deepcopy(w_in)  #avoid modifying global w within function\n",
    "    b = b_in\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "\n",
    "        # Calculate the gradient and update the parameters\n",
    "        dj_db,dj_dw = gradient_function(X, y, w, b)   ##None\n",
    "            \n",
    "        # Update Parameters using w, b, alpha and gradient\n",
    "        w = w - alpha * dj_dw               ##None\n",
    "        b = b - alpha * dj_db               ##None\n",
    "      \n",
    "        # Save cost J at each iteration\n",
    "        if i<100000:      # prevent resource exhaustion \n",
    "            J_history.append( cost_function(X, y, w, b))\n",
    "\n",
    "        # Print cost every at intervals 10 times or as many iterations if < 10\n",
    "        if i% math.ceil(num_iters / 10) == 0:\n",
    "            print(f\"Iteration {i:4d}: Cost {J_history[-1]:8.2f}   \")\n",
    "\n",
    "        \n",
    "    return w, b, J_history #return final w,b and J history for graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "e61b1e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration    0: Cost     2.03   \n",
      "Iteration 15000: Cost     0.72   \n",
      "Iteration 30000: Cost     0.68   \n",
      "Iteration 45000: Cost     0.64   \n",
      "Iteration 60000: Cost     0.61   \n",
      "Iteration 75000: Cost     0.58   \n",
      "Iteration 90000: Cost     0.56   \n",
      "Iteration 105000: Cost     0.54   \n",
      "Iteration 120000: Cost     0.54   \n",
      "Iteration 135000: Cost     0.54   \n",
      "b,w found by gradient descent: 0.01,[[ 0.1295019   0.02873465  0.06584426  0.00627961  0.00016721 -0.00363167]] \n"
     ]
    }
   ],
   "source": [
    "# calculate model weights with functions\n",
    "\n",
    "w, b = initial_zeros(X)\n",
    "\n",
    "dw = np.zeros_like(w)\n",
    "db = np.array([0.])\n",
    "\n",
    "cost_history = []\n",
    "num_iters = 150000\n",
    "learning_rate = 5.0e-7\n",
    "# run gradient descent \n",
    "w_final, b_final, J_hist = gradient_descent(X, Y, w, b,\n",
    "                                                    calculate_cost, calculate_grads, \n",
    "                                                    learning_rate, num_iters)\n",
    "print(f\"b,w found by gradient descent: {b_final:0.2f},{w_final} \")\n",
    "m,_ = X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb18b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.express as px\n",
    "# px.line(J_hist )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbf2fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "c6bee64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration    0: Cost     2.65   \n",
      "Iteration 15000: Cost     0.72   \n",
      "Iteration 30000: Cost     0.68   \n",
      "Iteration 45000: Cost     0.64   \n",
      "Iteration 60000: Cost     0.61   \n",
      "Iteration 75000: Cost     0.58   \n",
      "Iteration 90000: Cost     0.56   \n",
      "Iteration 105000: Cost     0.54   \n",
      "Iteration 120000: Cost     0.54   \n",
      "Iteration 135000: Cost     0.54   \n"
     ]
    }
   ],
   "source": [
    "# calculate model weights with np logic\n",
    "\n",
    "w, b = initial_zeros(X)\n",
    "dw = np.zeros_like(w)\n",
    "db = np.array([0.])\n",
    "\n",
    "cost_history = []\n",
    "num_iters = 150000\n",
    "learning_rate = 5.0e-7\n",
    "\n",
    "# loop thorugh gradient descent steps for number of iterations\n",
    "for i in range(num_iters):\n",
    "\n",
    "    \n",
    "    # set training_exp, features num \n",
    "    m, n = X.shape\n",
    "    \n",
    "    # forward_prop\n",
    "    Y_hat = np.dot(w, X.T) + b\n",
    "\n",
    "    # calc grads\n",
    "    db = np.mean(Y_hat - Y)\n",
    "    dw = np.sum(((Y_hat - Y) * X.T), axis=1) / m\n",
    "    \n",
    "    # Update Parameters using w, b, learning_rate and gradient\n",
    "    w = w - learning_rate * dw               \n",
    "    b = b - learning_rate * db   \n",
    "    \n",
    "    cost = np.sum((Y_hat - Y)**2 ) / (2*m)    \n",
    "    \n",
    "    if i<100000:      # prevent resource exhaustion \n",
    "            cost_history.append(cost)\n",
    "\n",
    "    # Print cost every at intervals 10 times or as many iterations if < 10\n",
    "    if i% math.ceil(num_iters / 10) == 0:\n",
    "        print(f\"Iteration {i:4d}: Cost {cost_history[-1]:8.2f}   \")\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "b05d3dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.express as px\n",
    "# px.line(cost_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "b6962dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set test variables\n",
    "test_df\n",
    "X_test = test_df.drop(columns=['target']).values\n",
    "Y_test = test_df['target'].values\n",
    "X_test.shape, Y_test.shape\n",
    "\n",
    "m,n = X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "1920cbc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.54048579, 2.18452727, 1.8916837 , ..., 1.22712008, 1.24225175,\n",
       "        1.35354649]])"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict all prices for test dataset\n",
    "Y_hat_test = np.dot(w, X_test.T) + b\n",
    "Y_hat_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "10b8a679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y_test</th>\n",
       "      <th>Y_hat_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.306</td>\n",
       "      <td>2.540486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.306</td>\n",
       "      <td>2.184527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.306</td>\n",
       "      <td>1.891684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.306</td>\n",
       "      <td>1.657910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.306</td>\n",
       "      <td>1.404975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6875</th>\n",
       "      <td>2.306</td>\n",
       "      <td>1.400506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6876</th>\n",
       "      <td>2.306</td>\n",
       "      <td>1.316108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6877</th>\n",
       "      <td>2.306</td>\n",
       "      <td>1.227120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6878</th>\n",
       "      <td>2.306</td>\n",
       "      <td>1.242252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6879</th>\n",
       "      <td>2.306</td>\n",
       "      <td>1.353546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6880 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Y_test  Y_hat_test\n",
       "0      2.306    2.540486\n",
       "1      2.306    2.184527\n",
       "2      2.306    1.891684\n",
       "3      2.306    1.657910\n",
       "4      2.306    1.404975\n",
       "...      ...         ...\n",
       "6875   2.306    1.400506\n",
       "6876   2.306    1.316108\n",
       "6877   2.306    1.227120\n",
       "6878   2.306    1.242252\n",
       "6879   2.306    1.353546\n",
       "\n",
       "[6880 rows x 2 columns]"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicitons to df\n",
    "data = {'Y_test':list(Y_test)[0], 'Y_hat_test':list(Y_hat_test)[0]}\n",
    "results_df = pd.DataFrame(data)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167d669c",
   "metadata": {},
   "source": [
    "mape = mean ( (actual - forecast) / actual )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "c60fdea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 6880), (1, 6880))"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sey Y & X shape (so calc below don't get cross)\n",
    "m, n = X_test.shape\n",
    "\n",
    "Y_test = test_df.target.values.reshape(1,m)\n",
    "Y_test.shape, Y_hat_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "4c5fd6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mape 0.14065267307846\n",
      "sk_rmse 1.051720814580968\n",
      "rmse 1.051720814580968\n"
     ]
    }
   ],
   "source": [
    "# calculate error metrics\n",
    "print('mape',  np.mean((Y_test - Y_hat_test) / Y_hat_test))\n",
    "\n",
    "import math\n",
    "print('sk_rmse', math.sqrt(mean_squared_error(Y_test, Y_hat_test)))\n",
    "print('rmse', np.sqrt(np.mean((Y_hat_test - Y_test )**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acd7aa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c245352f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
